{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능 최적화를 위해 텐서 내의 모든 객체는 같은 타입의 숫자여야 하고, 파이토치는 실행 중에 이런 숫자 타입을 계속 추첮하고 있어야 한다.\n",
    "\n",
    "텐서의 기본 데이터 타입은 32비트 부동소수점이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "double_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_points = torch.tensor([[1,2], [3,4]], dtype=torch.short)\n",
    "short_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points = torch.zeros(10, 2).double()\n",
    "double_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points = torch.zeros(10, 2).to(torch.double)\n",
    "double_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4511,  0.8236, -1.2383, -1.2843,  0.2402], dtype=torch.float64)\n",
      "tensor([-1,  0, -1, -1,  0], dtype=torch.int16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.4511, 0.0000, 1.2383, 1.2843, 0.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_64 = torch.randn(5, dtype=torch.double)\n",
    "print(points_64)\n",
    "points_short = points_64.to(torch.short)\n",
    "print(points_short)\n",
    "points_64 * points_short # 파이토치 1.3 부터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "torch.transpose(input, dim0, dim1) → Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3,2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_t = torch.transpose(a, 0, 1)\n",
    "a_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_t = a_t.transpose(1, 0)\n",
    "a_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "탠서 내부 값은 실제로는 torch.Storage인스턴스로 관리한다.   \n",
    "텐서는 storage에 담긴 데이터를 보여주는 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62664/2923139482.py:2: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  points.storage()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "points_storage = points.storage()\n",
    "print(points_storage[0])\n",
    "print(points.storage()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서는 참조 하고 있는 것이기 때문에 storage 값을 바꾸면 텐서도 바뀜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_storage[0] = 2.0\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zero_() 처럼 _로 끝나는 함수들은 변수에 저장된 값들을 바꾸는 역할을 한다.   \n",
    "_로 끝나지 않는 모든 메소드들은 원래 텐서는 그대로 두고 새로운 텐서를 만들어 넘겨준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3,2)\n",
    "a.zero_()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size(shape) : 텐서의 각 차원별로 들어가는 요소의 수를 표시한 튜플   \n",
    "offset : 텐서의 첫 번째 요소를 가리키는 색인 값   \n",
    "stride : 각 차원에서 다음 요소를 가리키고 싶을 떄 실제 저장 공간상에서 몇 개의 요소를 건너 뛰어야 하는지를 알려주는 숫자\n",
    "```\n",
    "point[i][j] = sotrage_offset + stride[0]*i + stride[1]*j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_points = points[1]\n",
    "second_points.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n",
      "tensor([5., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(second_points.size())\n",
    "print(second_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "print(points.stride())\n",
    "print(second_points.stride())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  1.],\n",
       "        [10.,  3.],\n",
       "        [ 2.,  1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_points[0] = 10.0\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 복사를 하면 서브텐서를 새 텐서로 복사해서 만듦\n",
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_points = points[1].clone()\n",
    "second_points[0] = 10.0\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Tensor.data_ptr\n",
    "```\n",
    "Tensor.data_ptr() → int\n",
    "```\n",
    "Returns the address of the first element of self tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[id 값에대한 stack overflow](https://stackoverflow.com/questions/67289617/pytorch-tensor-storages-have-the-same-id-when-calling-the-storage-method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python의 id()는 객체의 정체성을 반환한다. 이 id는 객체의 수명 동안 고유하고 일정하다.  \n",
    "``` print(id(points.storage()) == id(second_points.storage())) ```   \n",
    "여기서 points.storage()와 second_points.storage()는 호출 후 바로 사용이 끝나고, Python의 **가비지 콜렉터(Garbage Collector)**에 의해 삭제될 수 있다. 만약 points.storage()가 삭제된 후에 second_points.storage()가 생성된다면, 두 객체는 동일한 메모리 주소를 사용할 가능성이 있으므로 id가 같은 값을 가질 수 있다.   \n",
    "\n",
    "하지만 가비지 콜렉터의 동작 타이밍이나 객체 생성 순서에 따라 다른 값을 가져서 False가 반환될 수도 있다.      \n",
    "\n",
    "``` print(id(points.storage()) is id(second_points.storage())) ```   \n",
    "다음 코드는 print가 끝나면 가비지 콜렉터가 수집하기 때문에 False가 나오게 된다.   \n",
    "\n",
    "만약 둘이 같은 데이터인지 확인하려면, .data_ptr()을 사용해서 둘이 같은 요소를 공유하는지 확인하는 것이 나은 선택이 될 수 있다.\n",
    "\n",
    "[is vs == 에 관한 stack overflow](https://stackoverflow.com/questions/132988/is-there-a-difference-between-and-is)   \n",
    "다음 글에 따르면 is는 객체가 같은지를 확인하고, ==는 변수가 참조하는 객체가 같은지를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_points = points[1]\n",
    "# 둘다 같은 storage를 시작 요소의 주소값은 당연히 같다.\n",
    "print(points.storage().data_ptr() == second_points.storage().data_ptr())\n",
    "# ????\n",
    "print(id(points.storage()) == id(second_points.storage()))\n",
    "# 둘다 같은 storage이므로 값도 같다.\n",
    "print(points.storage()[2] == second_points.storage()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128132029013872\n",
      "128132029013680\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_t = points.t()\n",
    "\n",
    "a,b=id(points.storage()),id(points_t.storage())\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.storage().data_ptr()==points_t.storage().data_ptr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contiguous()함수를 사용하면 인접한 tensor를 만들 수 있다.\n",
    "points_t_cont = points_t.contiguous()\n",
    "points_t_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(points_t.stride())\n",
    "print(points_t_cont.stride())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU를 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 요소에 특정 상수를 곱하는 등의 텐서 연산은 GPU에서 수행된다.\n",
    "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.,  2.],\n",
       "        [10.,  6.],\n",
       "        [ 4.,  2.]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_gpu2 = 2 * points.to(device='cuda')\n",
    "point_gpu2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.,  2.],\n",
      "        [10.,  6.],\n",
      "        [ 4.,  2.]], device='cuda:0')\n",
      "tensor([[ 8.,  2.],\n",
      "        [10.,  6.],\n",
      "        [ 4.,  2.]], device='cuda:0')\n",
      "tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n"
     ]
    }
   ],
   "source": [
    "points_gpu = points\n",
    "print(point_gpu2)\n",
    "points_gpu = points.cuda()\n",
    "print(point_gpu2)\n",
    "points_cpu = points_gpu.cpu()\n",
    "print(points_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
