{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(3) # 크기가 3인 1차원 텐서를 만들고 1로 채우기\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] = 2.0\n",
    "a[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 89p\n",
    "### 텐서나 넘파이 배열은 파이썬 객체가 아닌 언박싱된 C언어의 숫자 타입을 포함한 연속적인 메모리가 할당되고 이에 대한 뷰를 제공한다. >> c언어의 숫자 타입을 사용한다는 뜻."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 각 요소는 32비트(4바이트)float타입이다. \n",
    "print(a.dtype)\n",
    "print(a[1].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0]) # 리스트도 당연히 인자로 됨\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 1.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(points[0]), float(points[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = [1,2,3,4] # 소괄호가 되는게 신기해서 list도 되나 확인함\n",
    "list[0],list[1],list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "print(points.shape)\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 데이터를 흑백으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "img_1 = torch.randn(3, 5, 5)  # [채널, 행, 열]\n",
    "img_2 = torch.randn(5, 5, 3)  # [행, 열, 채널]\n",
    "\n",
    "# RGB 채널 참조\n",
    "print(img_1[-3].shape)  # (5, 5), 채널이 첫 번째 차원\n",
    "print(img_2[-3].shape)  # (5, 5), 채널이 마지막 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4191,  2.0126,  0.6983, -2.0143,  2.1529],\n",
      "         [ 0.0378,  1.8441,  0.3956, -1.7088,  1.2046],\n",
      "         [-1.5089,  0.0125, -1.5309, -0.7492, -1.8526],\n",
      "         [-0.5963,  0.6359, -0.2701, -1.8439,  0.2477],\n",
      "         [-0.8653, -2.1381, -1.7105, -1.9565,  1.1573]],\n",
      "\n",
      "        [[ 0.0901, -0.6128, -1.5453, -0.3724,  0.9097],\n",
      "         [-0.8483, -0.4179, -1.4720, -0.7114,  1.6299],\n",
      "         [ 2.0467, -2.9343,  0.7537, -0.0783,  1.7529],\n",
      "         [-0.5254,  0.2190,  1.1582, -0.3140,  1.8583],\n",
      "         [-0.8087, -1.1784, -1.4031,  1.1891,  0.4616]],\n",
      "\n",
      "        [[ 0.8568,  1.2256, -0.9270, -0.2133, -0.2199],\n",
      "         [ 0.1268, -0.5539,  1.6500,  1.0087, -2.6191],\n",
      "         [ 0.9202, -0.2447, -1.1638, -0.3775, -0.1074],\n",
      "         [ 0.8161,  1.4235,  2.3678, -0.3060,  0.1983],\n",
      "         [ 1.0594, -0.0482,  0.2501,  0.4283, -1.0515]]])\n"
     ]
    }
   ],
   "source": [
    "print(img_1)  # (5, 5), 채널이 첫 번째 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4191,  2.0126,  0.6983, -2.0143,  2.1529],\n",
      "        [ 0.0378,  1.8441,  0.3956, -1.7088,  1.2046],\n",
      "        [-1.5089,  0.0125, -1.5309, -0.7492, -1.8526],\n",
      "        [-0.5963,  0.6359, -0.2701, -1.8439,  0.2477],\n",
      "        [-0.8653, -2.1381, -1.7105, -1.9565,  1.1573]])\n"
     ]
    }
   ],
   "source": [
    "print(img_1[-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 93p \n",
    "### RGB채널은 0번 혹은 1번 차원에 있다.두 경우 모두 뒤에서 부터 세 번째 차원이므로 RGB 채널은 -3번 차원에 있는 것으로 일반화 할 수 있다. << 가장 뒤에 2개는 행, 열일테니 -3번째는 당연히 RGB값이 나온 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = torch.randn(3, 5, 5) # [채널 크기, 행 크기, 열 크기]\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])\n",
    "\n",
    "batch_t = torch.randn(2, 3, 5, 5) # 배치 크기 2, [채널 크기, 행 크기, 열 크기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_naive = img_t.mean(-3) # -1, -2, -3 층 의  평균\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "img_gray_naive.shape, batch_gray_naive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7886,  0.2605, -0.1324, -1.3133,  0.1325],\n",
       "        [-0.3529, -1.3788,  0.8662, -0.2418,  1.0876],\n",
       "        [ 1.3358, -0.2636, -0.8288,  0.7054,  0.6459],\n",
       "        [-0.2129, -0.9313,  0.6914, -0.2465,  0.6578],\n",
       "        [ 0.8677, -0.8764, -0.2207,  0.6798,  0.6121]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4769) tensor(1.3710) tensor(-1.4821)\n",
      "0.7885956764221191\n"
     ]
    }
   ],
   "source": [
    "print(img_t[0, 0, 0], img_t[1, 0, 0], img_t[2, 0, 0])\n",
    "print((float(img_t[0, 0, 0])+ float(img_t[1, 0, 0])+ float(img_t[2, 0, 0]))/3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**squeeze** 함수는 Tensor의 차원을 줄이는 함수로, 설정한 차원을 제거 해 준다.\n",
    "\n",
    "따로 차원을 설정하지 않으면 1인 차원을 모두 제거한다. 1인 차원이 여러개 있어도 여러개를 전부 제거한다.\n",
    "\n",
    "반대로 **unsqueeze** 함수는 squeeze 함수와 반대로 차원을 늘려주는 함수인데, 1인 차원을 생성한다. unsqueeze 함수를 사용할 땐 어느 차원에 1인 차원을 생성을 할 것인지를 지정 해 주어야만 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2126]],\n",
      "\n",
      "        [[0.7152]],\n",
      "\n",
      "        [[0.0722]]])\n",
      "torch.Size([3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze(-1)\n",
    "print(unsqueezed_weights)\n",
    "print(unsqueezed_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch weight      :  torch.Size([2, 3, 5, 5]) \n",
      "batch gray weight :  torch.Size([2, 5, 5]) \n",
      "img weights       :  torch.Size([3, 5, 5]) \n",
      "img gray weights  :  torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "# 3x5x5 와 3x1x1를 곱함 << 브로드캐스팅 (크기가 같거나, 한쪽이 1이거나)\n",
    "img_weights = (img_t * unsqueezed_weights)\n",
    "# 2x3x5x5 와 3x1x1를 곱함\n",
    "batch_weights = (batch_t * unsqueezed_weights)\n",
    "# 3x5x5<<5x5가 3개, 이를 더한다>> 5x5차원 하나로 나옴\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "# 2x3x5x5<< 3x5x5가 2개, 이를 -3차원 기준으로 더한다 >> 5x5차원의 값이 2개로 나옴 2x5x5\n",
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "print('batch weight      : ', batch_weights.shape,\n",
    "      '\\nbatch gray weight : ',batch_gray_weighted.shape,\n",
    "      '\\nimg weights       : ', img_weights.shape,\n",
    "      '\\nimg gray weights  : ',img_gray_weighted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 5])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_weighted_fancy = torch.einsum('...chw,c->...hw', img_t, weights)\n",
    "batch_gray_weighted_fancy = torch.einsum('...chw,c->...hw', batch_t, weights)\n",
    "batch_gray_weighted_fancy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서의 이름 붙이기 아직은 실험적인 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "batch named: torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "# refine_names << 이미 만들고 나중에 이름을 붙일때, 쓰는 함수\n",
    "img_named =  img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "print(\"img named:\", img_named.shape, img_named.names)\n",
    "print(\"batch named:\", batch_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "weights_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 1]), ('channels', 'rows', 'columns'))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이름 설정시 자기가 알아서 차원을 알맞게 맞춰 준다.\n",
    "weights_aligned = weights_named.align_as(img_named)\n",
    "weights_aligned.shape, weights_aligned.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), ('rows', 'columns'))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named = (img_named * weights_aligned).sum('channels')\n",
    "gray_named.shape, gray_named.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error when attempting to broadcast dims ['channels', 'rows', 'columns'] and dims ['channels']: dim 'columns' and dim 'channels' are at the same position from the right but do not match.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 이름이 다른 차원을 결합하면, 에러\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m gray_named \u001b[38;5;241m=\u001b[39m (\u001b[43mimg_named\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights_named\u001b[49m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error when attempting to broadcast dims ['channels', 'rows', 'columns'] and dims ['channels']: dim 'columns' and dim 'channels' are at the same position from the right but do not match."
     ]
    }
   ],
   "source": [
    "# 이름이 다른 차원을 결합하면, 에러\n",
    "gray_named = (img_named[..., :3] * weights_named).sum('channels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), (None, None))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_plain = gray_named.rename(None)\n",
    "gray_plain.shape, gray_plain.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
